llama-cpp-python>=0.2.0
watchdog>=6.0.0
requests>=2.28.0
huggingface_hub>=0.16.0

[dev]
pytest>=7.0
black>=22.0
flake8>=5.0
